{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_squared_log_error\n",
    "import tqdm, sys, os, gc, argparse, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "path = '../data/'\n",
    "\n",
    "train_files = os.listdir(path+'train')\n",
    "train_df = pd.DataFrame()\n",
    "for filename in tqdm.tqdm(train_files):\n",
    "    tmp = pd.read_csv(path+'train/'+filename)\n",
    "    tmp['file'] = filename\n",
    "    train_df = pd.concat([train_df, tmp], axis=0, ignore_index=True)\n",
    "\n",
    "test_files = os.listdir(path+'test')\n",
    "test_df = pd.DataFrame()\n",
    "for filename in tqdm.tqdm(test_files):\n",
    "    tmp = pd.read_csv(path+'test/'+filename)\n",
    "    tmp['file'] = filename\n",
    "    test_df = pd.concat([test_df, tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['n_bid1','n_bid2','n_ask1','n_ask2']\n",
    "tmp_df = train_df[train_df['file']=='snapshot_sym7_date22_pm.csv'].reset_index(drop=True)[-500:]\n",
    "tmp_df = tmp_df.reset_index(drop=True).reset_index()\n",
    "for num, col in enumerate(cols):\n",
    "    plt.figure(figsize=(20,5))\n",
    "   \n",
    "    plt.subplot(4,1,num+1)\n",
    "    plt.plot(tmp_df['index'],tmp_df[col])\n",
    "    plt.title(col)\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for num, col in enumerate(cols):\n",
    "    plt.plot(tmp_df['index'],tmp_df[col],label=col)\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "for num, col in enumerate(cols):\n",
    "    \n",
    "    plt.plot(tmp_df['index'],tmp_df[col],label=col)\n",
    "    \n",
    "plt.plot(tmp_df['index'],tmp_df['n_midprice'],label=\"n_midprice\",lw=10)\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['wap1'] = (train_df['n_bid1']*train_df['n_bsize1'] + train_df['n_ask1']*train_df['n_asize1'])/(train_df['n_bsize1'] + train_df['n_asize1'])\n",
    "test_df['wap1'] = (test_df['n_bid1']*test_df['n_bsize1'] + test_df['n_ask1']*test_df['n_asize1'])/(test_df['n_bsize1'] + test_df['n_asize1'])\n",
    "\n",
    "tmp_df = train_df[train_df['file']=='snapshot_sym7_date22_pm.csv'].reset_index(drop=True)[-500:]\n",
    "tmp_df = tmp_df.reset_index(drop=True).reset_index()\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(tmp_df['index'], tmp_df['wap1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # 时间相关特征\n",
    "train_df['hour'] = train_df['time'].apply(lambda x:int(x.split(':')[0]))\n",
    "test_df['hour'] = test_df['time'].apply(lambda x:int(x.split(':')[0]))\n",
    "\n",
    "train_df['minute'] = train_df['time'].apply(lambda x:int(x.split(':')[1]))\n",
    "test_df['minute'] = test_df['time'].apply(lambda x:int(x.split(':')[1]))\n",
    "\n",
    "# 入模特征\n",
    "cols = [f for f in test_df.columns if f not in ['uuid','time','file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name, seed = 2023):\n",
    "    folds = 5\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros([train_x.shape[0], 3])\n",
    "    test_predict = np.zeros([test_x.shape[0], 3])\n",
    "    cv_scores = []\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "       \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.15, 'depth': 6, 'bootstrap_type':'Bernoulli','random_seed':2023,\n",
    "                      'od_type': 'Iter', 'od_wait': 1000, 'random_seed': 11, 'allow_writing_files': False,\n",
    "                      'loss_function': 'MultiClass'}\n",
    "            \n",
    "            model = clf(iterations=1000, task_type=\"GPU\", **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      metric_period=200,\n",
    "                      use_best_model=True, \n",
    "                      cat_features=[],\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)\n",
    "            test_pred = model.predict_proba(test_x)\n",
    "        \n",
    "        oof[valid_index] = val_pred\n",
    "        test_predict += test_pred / kf.n_splits\n",
    "        \n",
    "        F1_score = f1_score(val_y, np.argmax(val_pred, axis=1), average='macro')\n",
    "        cv_scores.append(F1_score)\n",
    "        print(cv_scores)\n",
    "        \n",
    "    return oof, test_predict\n",
    "    \n",
    "train_df_result = pd.DataFrame()\n",
    "test_df_result = pd.DataFrame()\n",
    "for label in ['label_5','label_10','label_20','label_40','label_60']:\n",
    "    print(f'=================== {label} ===================')\n",
    "    cat_oof, cat_test = cv_model(CatBoostClassifier, train_df[cols], train_df[label], test_df[cols], 'cat')\n",
    "    train_df_result[label] = np.argmax(cat_oof, axis=1)\n",
    "    test_df_result[label] = np.argmax(cat_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "test_df_csv = pd.DataFrame()\n",
    "train_df_csv = copy.deepcopy(train_df)\n",
    "test_df_csv = copy.deepcopy(test_df)\n",
    "for label in ['label_5','label_10','label_20','label_40','label_60']:\n",
    "    test_df_csv[label] = test_df_result[label]\n",
    "# 指定输出文件夹路径\n",
    "output_dir = './baseline/submit'\n",
    "\n",
    "# 如果文件夹不存在则创建\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 首先按照'file'字段对 dataframe 进行分组\n",
    "grouped = test_df_csv.groupby('file')\n",
    "\n",
    "# 对于每一个group进行处理\n",
    "for file_name, group in grouped:\n",
    "    # 选择你所需要的列\n",
    "    selected_cols = group[['uuid', 'label_5', 'label_10', 'label_20', 'label_40', 'label_60']]\n",
    "    \n",
    "    # 将其保存为csv文件，file_name作为文件名\n",
    "    selected_cols.to_csv(os.path.join(output_dir, f'{file_name}'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# train_df_csv = pd.DataFrame()\n",
    "# test_df_csv = pd.DataFrame()\n",
    "# train_df_csv = copy.deepcopy(train_df)\n",
    "# test_df_csv = copy.deepcopy(test_df)\n",
    "# for label in ['label_5','label_10','label_20','label_40','label_60']:\n",
    "#     test_df_csv[label] = test_df_result[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
